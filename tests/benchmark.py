import multiprocessing as mp
import time

import cv2

from yolo_detector import YOLOv8Detector


def run_benchmark():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼ˆä½¿ç”¨çœŸå®æˆªå›¾æµç¨‹ï¼‰")
    print("=" * 60)

    # åˆå§‹åŒ–
    model = YOLOv8Detector()
    crop_size = 256

    print(f"\næµ‹è¯•é…ç½®:")
    print(f"   æˆªå›¾åŒºåŸŸ: {crop_size}x{crop_size}")
    print(f"   YOLO æ¨¡å‹: {model.img_size}x{model.img_size}")
    print(f"   Provider: {model.session.get_providers()[0]}")

    # ==================== æµ‹è¯•1ï¼šçº¯æˆªå›¾é€Ÿåº¦ï¼ˆä½¿ç”¨ screen_captureï¼‰====================
    print("\n" + "=" * 60)
    print("æµ‹è¯•1: çº¯æˆªå›¾é€Ÿåº¦ï¼ˆä½¿ç”¨çœŸå®æ•è·æµç¨‹ï¼Œ100æ¬¡ï¼‰")
    print("=" * 60)

    from screen_capture import capture_screen

    frame_queue = mp.Queue(maxsize=10)
    capture_ready_event = mp.Event()

    # å¯åŠ¨æˆªå›¾è¿›ç¨‹
    capture_process = mp.Process(
        target=capture_screen,
        args=(frame_queue, capture_ready_event, crop_size),
        daemon=True
    )
    capture_process.start()
    capture_ready_event.wait()  # ç­‰å¾…æˆªå›¾è¿›ç¨‹å°±ç»ª
    time.sleep(0.5)  # è®©é˜Ÿåˆ—å¡«å……

    capture_times = []
    for i in range(100):
        start = time.perf_counter()
        img = frame_queue.get()  # ä»é˜Ÿåˆ—è·å–
        capture_times.append((time.perf_counter() - start) * 1000)

    avg_capture = sum(capture_times) / len(capture_times)
    min_capture = min(capture_times)
    max_capture = max(capture_times)

    print(f"   å¹³å‡: {avg_capture:.2f}ms")
    print(f"   æœ€å¿«: {min_capture:.2f}ms")
    print(f"   æœ€æ…¢: {max_capture:.2f}ms")
    print(f"   ç†è®ºæœ€å¤§ FPS: {1000 / avg_capture:.1f}")

    # ==================== æµ‹è¯•2ï¼šçº¯ YOLO æ¨ç†é€Ÿåº¦ ====================
    print("\n" + "=" * 60)
    print("æµ‹è¯•2: çº¯ YOLO æ¨ç†é€Ÿåº¦ï¼ˆ100æ¬¡ï¼‰")
    print("=" * 60)

    # å…ˆä»é˜Ÿåˆ—è·å–ä¸€å¼ å›¾
    img_bgra = frame_queue.get()
    img_bgr = cv2.cvtColor(img_bgra, cv2.COLOR_BGRA2BGR)

    inference_times = []
    for i in range(100):
        start = time.perf_counter()
        results = model.predict(img_bgr)
        inference_times.append((time.perf_counter() - start) * 1000)

    avg_inference = sum(inference_times) / len(inference_times)
    min_inference = min(inference_times)
    max_inference = max(inference_times)

    print(f"   å¹³å‡: {avg_inference:.2f}ms")
    print(f"   æœ€å¿«: {min_inference:.2f}ms")
    print(f"   æœ€æ…¢: {max_inference:.2f}ms")
    print(f"   ç†è®ºæœ€å¤§ FPS: {1000 / avg_inference:.1f}")

    # ==================== æµ‹è¯•3ï¼šå®Œæ•´æµç¨‹ï¼ˆæ¨¡æ‹ŸçœŸå®è¿è¡Œï¼‰====================
    print("\n" + "=" * 60)
    print("æµ‹è¯•3: å®Œæ•´æµç¨‹ï¼ˆé˜Ÿåˆ— + æˆªå›¾ + æ¨ç†ï¼Œ100æ¬¡ï¼‰")
    print("=" * 60)

    full_times = []
    queue_wait_times = []
    conversion_times = []
    actual_inference_times = []

    for i in range(100):
        full_start = time.perf_counter()

        # 1. ä»é˜Ÿåˆ—è·å–å›¾åƒï¼ˆæ¨¡æ‹Ÿè¿›ç¨‹é—´é€šä¿¡ï¼‰
        queue_start = time.perf_counter()
        img_bgra = frame_queue.get()
        queue_wait_times.append((time.perf_counter() - queue_start) * 1000)

        # 2. é¢œè‰²è½¬æ¢
        conversion_start = time.perf_counter()
        img_bgr = cv2.cvtColor(img_bgra, cv2.COLOR_BGRA2BGR)
        conversion_times.append((time.perf_counter() - conversion_start) * 1000)

        # 3. æ¨ç†
        inference_start = time.perf_counter()
        results = model.predict(img_bgr)
        actual_inference_times.append((time.perf_counter() - inference_start) * 1000)

        full_times.append((time.perf_counter() - full_start) * 1000)

    avg_full = sum(full_times) / len(full_times)
    min_full = min(full_times)
    max_full = max(full_times)
    avg_queue_wait = sum(queue_wait_times) / len(queue_wait_times)
    avg_conversion = sum(conversion_times) / len(conversion_times)
    avg_actual_inference = sum(actual_inference_times) / len(actual_inference_times)

    print(f"   å¹³å‡: {avg_full:.2f}ms")
    print(f"   æœ€å¿«: {min_full:.2f}ms")
    print(f"   æœ€æ…¢: {max_full:.2f}ms")
    print(f"   å®é™…æœ€å¤§ FPS: {1000 / avg_full:.1f}")

    # ==================== æ€§èƒ½åˆ†æï¼ˆè¯¦ç»†ç‰ˆï¼‰====================
    print("\n" + "=" * 60)
    print("æ€§èƒ½ç“¶é¢ˆåˆ†æï¼ˆè¯¦ç»†ï¼‰")
    print("=" * 60)

    queue_percent = (avg_queue_wait / avg_full) * 100
    conversion_percent = (avg_conversion / avg_full) * 100
    inference_percent = (avg_actual_inference / avg_full) * 100
    overhead_percent = 100 - queue_percent - conversion_percent - inference_percent

    print(f"   é˜Ÿåˆ—ç­‰å¾…: {avg_queue_wait:.2f}ms ({queue_percent:.1f}%)")
    print(f"   é¢œè‰²è½¬æ¢: {avg_conversion:.2f}ms ({conversion_percent:.1f}%)")
    print(f"   æ¨ç†è€—æ—¶: {avg_actual_inference:.2f}ms ({inference_percent:.1f}%)")
    print(f"   å…¶ä»–å¼€é”€: {overhead_percent:.1f}%")

    # åˆ¤æ–­ç“¶é¢ˆ
    if inference_percent > 50:
        print(f"\n   ğŸ”´ ä¸»è¦ç“¶é¢ˆ: YOLO æ¨ç†ï¼ˆ{inference_percent:.1f}%ï¼‰")
        print(f"   å»ºè®®: é™ä½æ¨¡å‹åˆ†è¾¨ç‡æˆ–ä½¿ç”¨é‡åŒ–æ¨¡å‹")
    elif queue_percent > 30:
        print(f"\n   ğŸŸ¡ æ¬¡è¦ç“¶é¢ˆ: é˜Ÿåˆ—ç­‰å¾…ï¼ˆ{queue_percent:.1f}%ï¼‰")
        print(f"   å»ºè®®: å¢å¤§é˜Ÿåˆ—å¤§å°æˆ–ä¼˜åŒ–æˆªå›¾é¢‘ç‡")
    else:
        print(f"\n   âœ… æ€§èƒ½å‡è¡¡")

    # ==================== æ¨èé…ç½® ====================
    print("\n" + "=" * 60)
    print("æ¨èé…ç½®")
    print("=" * 60)

    max_fps = int(1000 / avg_full * 0.9)  # ç•™ 10% ä½™é‡

    # æ ¹æ®å®é™… FPS è®¡ç®— KP
    target_fps = 60
    delay_factor = target_fps / max_fps
    safe_kp = 0.95 / delay_factor
    recommended_kp = round(safe_kp * 0.9, 2)  # ä¿å®ˆä¼°è®¡

    print(f'''
{{
    "CAPTURE_FPS": {max_fps},
    "INFERENCE_FPS": {max_fps},
    "PID_KP": {recommended_kp},
    "PID_KD": {0.05 + (delay_factor - 1) * 0.1:.2f}
}}
''')

    # ==================== ä¸ç®€å•æµ‹è¯•å¯¹æ¯” ====================
    print("\n" + "=" * 60)
    print("ä¸ç›´æ¥ mss æµ‹è¯•çš„å¯¹æ¯”")
    print("=" * 60)

    import mss
    import numpy as np

    with mss.mss() as sct:
        monitor = sct.monitors[1]
        crop_area = {
            'left': monitor['width'] // 2 - crop_size // 2,
            'top': monitor['height'] // 2 - crop_size // 2,
            'width': crop_size,
            'height': crop_size
        }

        direct_times = []
        for i in range(100):
            start = time.perf_counter()
            img = np.array(sct.grab(crop_area))
            img_bgr = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)
            results = model.predict(img_bgr)
            direct_times.append((time.perf_counter() - start) * 1000)

    avg_direct = sum(direct_times) / len(direct_times)

    print(f"   ç›´æ¥ mss æµ‹è¯•: {avg_direct:.2f}ms ({1000/avg_direct:.1f} FPS)")
    print(f"   çœŸå®æµç¨‹æµ‹è¯•: {avg_full:.2f}ms ({1000/avg_full:.1f} FPS)")
    print(f"   æ€§èƒ½å·®è·: {((avg_full - avg_direct) / avg_direct * 100):.1f}%")
    print(f"   å·®è·æ¥æº: é˜Ÿåˆ—é€šä¿¡å¼€é”€ ({avg_queue_wait:.2f}ms)")

    # æ¸…ç†è¿›ç¨‹
    capture_process.terminate()
    capture_process.join()

    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 60)


if __name__ == '__main__':
    # Windows å¤šè¿›ç¨‹å¿…éœ€
    mp.freeze_support()
    run_benchmark()
