import onnxruntime as ort

print("=" * 60)
print("ğŸ” ONNX Runtime Provider æ£€æµ‹")
print("=" * 60)

# è·å–æ‰€æœ‰å¯ç”¨çš„ Providers
available = ort.get_available_providers()
print(f"\nå½“å‰ç³»ç»Ÿæ”¯æŒçš„ Providers:")
for i, provider in enumerate(available, 1):
    print(f"   {i}. {provider}")

# æ£€æŸ¥æ˜¯å¦æ”¯æŒ GPU
gpu_providers = [p for p in available if 'CPU' not in p]

if gpu_providers:
    print(f"\næ£€æµ‹åˆ° GPU æ”¯æŒ:")
    for provider in gpu_providers:
        print(f"   â€¢ {provider}")

    # ç»™å‡ºå»ºè®®
    if 'DmlExecutionProvider' in available:
        print("\nå»ºè®®: ä½¿ç”¨ DmlExecutionProvider (é€‚ç”¨äº AMD/NVIDIA/Intel)")
    elif 'ROCMExecutionProvider' in available:
        print("\nå»ºè®®: ä½¿ç”¨ ROCMExecutionProvider (AMD ä¸“ç”¨)")
    elif 'CUDAExecutionProvider' in available:
        print("\nå»ºè®®: ä½¿ç”¨ CUDAExecutionProvider (NVIDIA ä¸“ç”¨)")
else:
    print(f"\næœªæ£€æµ‹åˆ° GPU æ”¯æŒï¼Œåªèƒ½ä½¿ç”¨ CPU")
    print("\nè§£å†³æ–¹æ³•:")
    print("   1. ç¡®è®¤å·²å®‰è£…æ˜¾å¡é©±åŠ¨")
    print("   2. å®‰è£… GPU ç‰ˆæœ¬çš„ ONNX Runtime:")
    print("      pip uninstall onnxruntime")
    print("      pip install onnxruntime-directml  # Windows (AMD/NVIDIA/Intel)")
    print("      # æˆ–")
    print("      pip install onnxruntime-gpu  # Linux (NVIDIA CUDA)")

print("\n" + "=" * 60)
